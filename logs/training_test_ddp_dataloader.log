2026-01-05 14:52:28 | GPU 0 | INFO | Shard path []
2026-01-05 14:52:28 | GPU 0 | INFO | Shard token counts {}
2026-01-05 14:52:28 | GPU 0 | INFO | Total tokens 0
2026-01-05 14:52:28 | GPU 0 | INFO | Shard start indices: {}
2026-01-05 14:52:28 | GPU 0 | INFO | Total sequences 0
2026-01-05 14:57:13 | GPU 0 | INFO | config: GPT2DataConfig(batch_size=16, block_size=1024, shakes_text_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/input.txt'), mps_fineweb_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/fineweb_edu_0048.npy'), gpu_audodl_fineweb_path=PosixPath('/root/autodl-tmp/kaggle-fineweb'), checkpoint_dir=PosixPath('/root/TinyTransformers/checkpoints'), checkpoint_every_n_shards=2, token_column='tokens', num_workers=32, ddp=False, rank=0, world_size=4, resume_checkpoint=None, log_level='DEBUG', shuffle=True, seed=1337, max_iters=5000, eval_interval=500, learning_rate=0.0006, weight_decay=1e-05, dropout=0.2, device='cuda', eval_iters=200, vocab_size=50304, n_embd=768, n_layer=12, n_head=12)
2026-01-05 14:59:41 | GPU 0 | INFO | config: GPT2DataConfig(batch_size=16, block_size=1024, shakes_text_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/input.txt'), mps_fineweb_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/fineweb_edu_0048.npy'), gpu_audodl_fineweb_path=PosixPath('/root/autodl-tmp/kaggle-fineweb'), checkpoint_dir=PosixPath('/root/TinyTransformers/checkpoints'), checkpoint_every_n_shards=2, token_column='tokens', num_workers=32, ddp=False, rank=0, world_size=4, resume_checkpoint=None, log_level='DEBUG', shuffle=True, seed=1337, max_iters=5000, eval_interval=500, learning_rate=0.0006, weight_decay=1e-05, dropout=0.2, device='cuda', eval_iters=200, vocab_size=50304, n_embd=768, n_layer=12, n_head=12)
2026-01-05 14:59:41 | GPU 0 | INFO | []
2026-01-05 15:01:52 | GPU 0 | INFO | config: GPT2DataConfig(batch_size=16, block_size=1024, shakes_text_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/input.txt'), mps_fineweb_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/fineweb_edu_0048.npy'), gpu_audodl_fineweb_path=PosixPath('/root/autodl-tmp/kaggle-fineweb'), checkpoint_dir=PosixPath('/root/TinyTransformers/checkpoints'), checkpoint_every_n_shards=2, token_column='tokens', num_workers=32, ddp=False, rank=0, world_size=4, resume_checkpoint=None, log_level='DEBUG', shuffle=True, seed=1337, max_iters=5000, eval_interval=500, learning_rate=0.0006, weight_decay=1e-05, dropout=0.2, device='cuda', eval_iters=200, vocab_size=50304, n_embd=768, n_layer=12, n_head=12)
2026-01-05 15:01:52 | GPU 0 | INFO | []
2026-01-05 15:05:53 | GPU 0 | INFO | config: GPT2DataConfig(batch_size=16, block_size=1024, shakes_text_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/input.txt'), mps_fineweb_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/fineweb_edu_0048.npy'), gpu_audodl_fineweb_path=PosixPath('/root/autodl-tmp/kaggle-fineweb'), checkpoint_dir=PosixPath('/root/TinyTransformers/checkpoints'), checkpoint_every_n_shards=2, token_column='tokens', num_workers=32, ddp=False, rank=0, world_size=4, resume_checkpoint=None, log_level='DEBUG', shuffle=True, seed=1337, max_iters=5000, eval_interval=500, learning_rate=0.0006, weight_decay=1e-05, dropout=0.2, device='cuda', eval_iters=200, vocab_size=50304, n_embd=768, n_layer=12, n_head=12)
2026-01-05 15:07:57 | GPU 0 | INFO | config: GPT2DataConfig(batch_size=16, block_size=1024, shakes_text_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/input.txt'), mps_fineweb_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/fineweb_edu_0048.npy'), gpu_audodl_fineweb_path=PosixPath('/root/autodl-tmp/kaggle-fineweb'), checkpoint_dir=PosixPath('/root/TinyTransformers/checkpoints'), checkpoint_every_n_shards=2, token_column='tokens', num_workers=32, ddp=False, rank=0, world_size=4, resume_checkpoint=None, log_level='DEBUG', shuffle=True, seed=1337, max_iters=5000, eval_interval=500, learning_rate=0.0006, weight_decay=1e-05, dropout=0.2, device='cuda', eval_iters=200, vocab_size=50304, n_embd=768, n_layer=12, n_head=12)
2026-01-05 15:07:57 | GPU 0 | INFO | []
2026-01-05 15:15:34 | GPU 0 | INFO | config: GPT2DataConfig(batch_size=16, block_size=1024, shakes_text_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/input.txt'), mps_fineweb_path=PosixPath('/root/TinyTransformers/lecture_code_and_data/fineweb_edu_0048.npy'), gpu_audodl_fineweb_path=PosixPath('/root/autodl-tmp/kaggle-fineweb'), checkpoint_dir=PosixPath('/root/TinyTransformers/checkpoints'), checkpoint_every_n_shards=2, token_column='tokens', num_workers=32, ddp=False, rank=0, world_size=4, resume_checkpoint=None, log_level='DEBUG', shuffle=True, seed=1337, max_iters=5000, eval_interval=500, learning_rate=0.0006, weight_decay=1e-05, dropout=0.2, device='cpu', eval_iters=200, vocab_size=50304, n_embd=768, n_layer=12, n_head=12)
2026-01-05 15:15:34 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/train/fineweb_edu_0030.npy
2026-01-05 15:21:33 | GPU 0 | INFO | Start a new round
2026-01-05 15:21:33 | GPU 0 | INFO | Manual test file read
2026-01-05 15:21:33 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/train/fineweb_edu_0030.npy
2026-01-05 15:23:41 | GPU 0 | INFO | Start a new round
2026-01-05 15:23:41 | GPU 0 | INFO | Manual test file read
2026-01-05 15:23:41 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/train/fineweb_edu_0030.npy
2026-01-05 15:23:41 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/test/fineweb_edu_0049.npy
2026-01-05 15:23:41 | GPU 0 | INFO | now do the dataset class test
2026-01-05 15:45:53 | GPU 0 | INFO | Start a new round
2026-01-05 15:45:53 | GPU 0 | INFO | Manual test file read
2026-01-05 15:45:53 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/train/fineweb_edu_0030.npy
2026-01-05 15:45:53 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/test/fineweb_edu_0049.npy
2026-01-05 15:45:53 | GPU 0 | INFO | now do the dataset class test
2026-01-05 15:48:38 | GPU 0 | INFO | Start a new round
2026-01-05 15:48:38 | GPU 0 | INFO | Manual test file read
2026-01-05 15:48:38 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/train/fineweb_edu_0030.npy
2026-01-05 15:48:38 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/test/fineweb_edu_0049.npy
2026-01-05 15:48:38 | GPU 0 | INFO | now do the dataset class test
2026-01-05 16:10:24 | GPU 0 | INFO | Start a new round
2026-01-05 16:10:24 | GPU 0 | INFO | Manual test file read
2026-01-05 16:10:24 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/train/fineweb_edu_0030.npy
2026-01-05 16:10:24 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/test/fineweb_edu_0049.npy
2026-01-05 16:10:24 | GPU 0 | INFO | now do the dataset class test
2026-01-05 16:16:21 | GPU 0 | INFO | Start a new round
2026-01-05 16:16:21 | GPU 0 | INFO | Manual test file read
2026-01-05 16:16:21 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/train/fineweb_edu_0030.npy
2026-01-05 16:16:21 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/test/fineweb_edu_0049.npy
2026-01-05 16:16:21 | GPU 0 | INFO | now do the dataset class test
2026-01-08 15:10:16 | GPU 0 | INFO | Start a new round
2026-01-08 15:10:16 | GPU 0 | INFO | Manual test file read
2026-01-08 15:10:16 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/train/fineweb_edu_0030.npy
2026-01-08 15:10:16 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/test/fineweb_edu_0049.npy
2026-01-08 15:10:16 | GPU 0 | INFO | now do the dataset class test
2026-01-08 15:11:31 | GPU 0 | INFO | Start a new round
2026-01-08 15:11:31 | GPU 0 | INFO | Manual test file read
2026-01-08 15:11:31 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/train/fineweb_edu_0030.npy
2026-01-08 15:11:31 | GPU 0 | INFO | /root/autodl-tmp/kaggle-fineweb/test/fineweb_edu_0049.npy
2026-01-08 15:11:31 | GPU 0 | INFO | now do the dataset class test
